import { InferenceClient } from "@huggingface/inference";
import dotenv from "dotenv";
import { storeToAzure } from "./uploadingToAzure";

dotenv.config();

const client = new InferenceClient(process.env.HF_TOKEN);

export const generateFromTogether = async (
    enhancedPrompt: any,
    userPrompt: string,
) => {
    try {
        const image: any = await client.textToImage({
            provider: "together",
            model: "black-forest-labs/FLUX.1-dev",
            inputs: `${userPrompt} and ${enhancedPrompt}`,
            parameters: { num_inference_steps: 5 },
        });

        const arrayBuffer = await image.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);
        const imageUrl = await storeToAzure(buffer, image?.type);

        return imageUrl;
    } catch (error) {
        console.log(error);
        throw new Error("No image generated by Hugging Face");
    }
};

export const generateFromReplicate = async (
    base64Img: string,
    enhancedPrompt: any,
    userPrompt: string,
) => {
    try {
        const imageBlob = new Blob([base64Img], { type: "image/jpeg" });

        const image: any = await client.imageToImage({
            provider: "replicate",
            model: "black-forest-labs/FLUX.2-klein-4B",
            inputs: imageBlob,
            parameters: {
                prompt: `${userPrompt} and ${enhancedPrompt}`,
            },
        });

        const arrayBuffer = await image.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);
        const imageUrl = await storeToAzure(buffer, image?.type);

        return imageUrl;
    } catch (error) {
        console.log(error);
        throw new Error("No image generated by Hugging Face");
    }
};

export const generateFromWaveSpeed = async (
    base64Img: string,
    enhancedPrompt: any,
    userPrompt: string,
) => {
    try {
        const imageBlob = new Blob([base64Img], { type: "image/jpeg" });

        const image: any = await client.imageToImage({
            provider: "wavespeed",
            model: "black-forest-labs/FLUX.2-dev",
            inputs: imageBlob,
            parameters: {
                prompt: `${userPrompt} and ${enhancedPrompt}`,
            },
        });

        const arrayBuffer = await image.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);
        const imageUrl = await storeToAzure(buffer, image?.type);

        return imageUrl;
    } catch (error) {
        console.log(error);
        throw new Error("No image generated by Hugging Face");
    }
};

export const generateFromFal = async (
    base64Img: string,
    enhancedPrompt: any,
    userPrompt: string,
) => {
    try {
        const imageBlob = new Blob([base64Img], { type: "image/jpeg" });

        const image: any = await client.imageToImage({
            provider: "fal-ai",
            model: "fal/Qwen-Image-Edit-2511-Multiple-Angles-LoRA",
            inputs: imageBlob,
            parameters: {
                prompt: `${userPrompt} and ${enhancedPrompt}`,
            },
        });

        const arrayBuffer = await image.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);
        const imageUrl = await storeToAzure(buffer, image?.type);

        return imageUrl;
    } catch (error) {
        console.log(error);
        throw new Error("No image generated by Hugging Face");
    }
};

export const generateFromWSTxt = async (
    enhancedPrompt: any,
    userPrompt: string,
) => {
    try {
        const image: any = await client.textToImage({
            provider: "wavespeed",
            model: "Tongyi-MAI/Z-Image-Turbo",
            inputs: `${userPrompt} and ${enhancedPrompt}`,
            parameters: { num_inference_steps: 5 },
        });

        const arrayBuffer = await image.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);
        const imageUrl = await storeToAzure(buffer, image?.type);

        return imageUrl;
    } catch (error) {
        console.log(error);
        throw new Error("No image generated by Hugging Face");
    }
};

export const generateFromFalTxt = async (
    enhancedPrompt: any,
    userPrompt: string,
) => {
    try {
        const image: any = await client.textToImage({
            provider: "fal-ai",
            model: "zai-org/GLM-Image",
            inputs: `${userPrompt} and ${enhancedPrompt}`,
            parameters: { num_inference_steps: 5 },
        });

        const arrayBuffer = await image.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);
        const imageUrl = await storeToAzure(buffer, image?.type);

        return imageUrl;
    } catch (error) {
        console.log(error);
        throw new Error("No image generated by Hugging Face");
    }
};

export const generateFromZAI = async (
    enhancedPrompt: any,
    userPrompt: string,
) => {
    try {
        const image: any = await client.textToImage({
            provider: "zai-org",
            model: "zai-org/GLM-Image",
            inputs: `${userPrompt} and ${enhancedPrompt}`,
            parameters: { num_inference_steps: 5 },
        });

        const arrayBuffer = await image.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);
        const imageUrl = await storeToAzure(buffer, image?.type);

        return imageUrl;
    } catch (error) {
        console.log(error);
        throw new Error("No image generated by Hugging Face");
    }
};

export const generateFromReplicateTxt = async (
    enhancedPrompt: any,
    userPrompt: string,
) => {
    try {
        const image: any = await client.textToImage({
            provider: "replicate",
            model: "Tongyi-MAI/Z-Image-Turbo",
            inputs: `${userPrompt} and ${enhancedPrompt}`,
            parameters: { num_inference_steps: 5 },
        });

        const arrayBuffer = await image.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);
        const imageUrl = await storeToAzure(buffer, image?.type);

        return imageUrl;
    } catch (error) {
        console.log(error);
        throw new Error("No image generated by Hugging Face");
    }
};
